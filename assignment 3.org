#+STARTUP: indent
#+OPTIONS: toc:nil num:nil
#+TITLE: ECON 497 Assignment 3
#+LaTeX_CLASS_OPTIONS: [article,letterpaper,times,10pt,margin=0.7in]
#+LATEX_HEADER: \usepackage[margin=0.7in]{geometry}
#+AUTHOR: %%AUTHOR%%

#+DATE: due: March 11^{th}, 2022
#+LaTeX_HEADER: \usepackage{lastpage}
#+LATEX_HEADER: \usepackage{fancyhdr}
#+LATEX_HEADER: \usepackage{amsmath}
#+LATEX_HEADER: \usepackage{bbm}
#+LATEX_HEADER: \pagestyle{fancy}
#+LATEX_HEADER: \chead{} %%AUTHOR%%
#+LATEX_HEADER: \lhead{total pages: \pageref{LastPage}}
#+LATEX_HEADER: \rhead{this is page \thepage}
#+LATEX_HEADER: \lfoot{}
#+LATEX_HEADER: \cfoot{ECON 497 Winter 2022}
#+LATEX_HEADER: \rfoot{}
#+LATEX: \renewcommand{\footrulewidth}{0.4pt}

#+LATEX: \linespread{1.5}

* Q1
Let $X:=(x_1,\ldots,x_n)$ be an iid sample from exponential ($theta$) distribution. likelihood function of the sample is then
\[ L(X|\theta) = \theta^n e^{-\theta \sum_1^n x_i} \]
and the log-likelihood \[l(X|\theta) = n\log(\theta) - \theta \sum x_i\]
So that the first-order condition for max-likelihood becomes \[ \partial_\theta l = \frac{n}{\theta} - \sum x_i = 0 \]
And thus the MLE estimator \[\hat{\theta}_{MLE} = \bar{X} = \frac{\sum_1^n x_i}{n} \]

The variance of the MLE estimator is \[\mathbbm{V}[\bar{X}] = n^{-2} \sum_1^n \mathbbm{V}[X_i] = n^{-1} \mathbbm{V}[X_i] = (n\theta^2)^{-1} \]
* Q2
Model $y_i = \beta_1 + \beta_2 x_i + \epsilon_i$
MLE of iid sample of size $n$
\[L(Y,X|\beta_1,\beta_2,\sigma) = (2\pi\sigma^2)^{-n/2} e^{-\frac{1}{2\sigma^2}\left(\sum y_i^2  + n\beta_1^2 + \beta_2\sum x_i^2  - 2\beta_1\sum y_i - 2\beta_2 \sum x_i y_i + 2\beta_1\beta_2\sum x_i \right)}\]
The log-likelihood
\[l(Y,X|\beta_1,\beta_2,\sigma) = const - n \log(\sigma) - \frac{1}{2\sigma^2}\left(\sum y_i - \beta_1 - \beta_2 x_i\right)^2 \]
So that the first-order conditions are
\begin{eqnarray}
\sigma \partial_{\beta_1} l & =  \sum \left( y_i - \beta_1 - \beta_2 x_i \right) & =  0 \\
\sigma \partial_{\beta_2} l & =  \sum \left( y_i - \beta_1 - \beta_2 x_i \right) x_i & =  0 \\
\partial_\sigma l & = -\frac{n}{\sigma} + \frac{1}{\sigma^3} \sum \left(y_i - \beta_1 - \beta_2 x_i \right)^2 & = 0
\end{eqnarray}

With the solution
\begin{eqnarray}
\hat{\beta_1}_{MLE}  = & \bar{y} - \hat{\beta_2}_{MLE} \bar{x} \\
\hat{\beta_2}_{MLE}  = & \frac{\sum y_i (x_i - \bar{x})}{\sum(x_i-\bar{x})^2} \\
\hat{\sigma}_{MLE}   = & \frac{1}{n}\sum\left( y_i - \hat{\beta_1} - \hat{\beta_2} x_i \right)^2
\end{eqnarray}

Note that the *MLE estimators of the slope and intercept are identical to the MSS estimators; maximizing likelihood corresponds to minimizing SSR*.
* Q3
Model $y_i = \beta x_i + \epsilon_i$
Residuals Sum of Squares $e_i^2 = (y_i - \beta x_i)^2$, so that first order condition on minimizing RSS is \[\partial_\beta \sum e_i^2 = 2 \sum (y_i - \beta x_i) x_i = 0 \]
Which immediately yields \[\hat\beta = \frac{\sum x_i y_i}{\sum x_i^2}\] as required.
Substituting $\mathbbm{E}[y_i] = \beta x_i$ from the model, we get
\[\mathbbm{E}[\hat\beta] = \frac{\sum x_i\beta x_i}{\sum x_i^2} = \beta\]
so $\hat\beta$ is an unbiased estimator of $\beta$.
Note that the variance of $\hat\beta$, assuming constant finite variance of $y_i$, is
\[\mathbbm{V}[\hat\beta] = \mathbbm{V}[y_i] \sum\left(\frac{x_i}{\sum x_i^2}\right)^2 = \frac{\sigma^2}{\sum x_i^2} \leq \frac{\sigma^2}{n\min(x_i^2)} \to 0 \]
Since the estimator is unbiased and is of vanishing variance, it is *consistent*: $p\lim \hat\beta = \delta(x-\beta)$

If the true model is $y_i = \beta x_i + \delta z_i + \epsilon_i$, we need to substitute this value into the expression for the expecation of $\hat\beta$ above:
\[\mathbbm{E}[\hat\beta] = \frac{\sum x_i (\beta x_i + \delta z_i)}{\sum x_i^2} \]
So that the bias
\[\mathbbm{B}[\hat\beta] =\mathbbm{E}[\hat\beta] - \beta = \beta + \frac{\sum x_i \delta z_i}{\sum x_i^2} -\beta = \delta\frac{\sum x_i z_i}{\sum x_i^2} \]

So if the truncated model estimator is $B := 0.16 >0$, while the extended model predicts $\hat\beta < 0$, we have from the omitted variable bias
\[ B - \beta = \delta \frac{\sum x_i z_i}{\sum x_i^2} = \delta \rho(x,z) \mathbbm{V}[z] > 0 \]
Since both $B$ and $-\beta$ are positive. If $\delta$ is assumed to be negative, we must have $\rho(x,z) \mathbbm{V}[z] < 0$ and therefore *the correlation between $x_i$ and $z_i$ is negative*.
